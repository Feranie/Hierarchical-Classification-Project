{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Feranie/Hierarchical-Classification-Project/blob/main/hierarchical_global_model_naives_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9B62arDgzhM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "77bfd389-96f0-44cd-d702-344f23785202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìñ Lecture du fichier d'entra√Ænement...\n",
            "Erreur lors de la lecture du fichier : [Errno 2] No such file or directory: '/content/GPCR-PfamTRA0.arff'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/GPCR-PfamTRA0.arff'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3989437733.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# Testa com alpha = 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1-3989437733.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_file_path, test_file_path, alpha)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# Cria leitor para arquivo de treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mtrain_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArffReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mtrain_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_arff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# L√™ arquivo de treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Converte dados de treino para array numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-3989437733.py\u001b[0m in \u001b[0;36mread_arff\u001b[0;34m(self, input_file)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Abre o arquivo em modo leitura com codifica√ß√£o UTF-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# Itera sobre cada linha do arquivo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/GPCR-PfamTRA0.arff'"
          ]
        }
      ],
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import numpy as np  # Biblioteca para opera√ß√µes num√©ricas e arrays\n",
        "import os  # Biblioteca para opera√ß√µes do sistema operacional\n",
        "from sklearn.datasets import load_iris  # Importa dataset iris do sklearn (n√£o usado no c√≥digo)\n",
        "from collections import defaultdict  # Importa defaultdict para criar dicion√°rios com valores padr√£o\n",
        "\n",
        "class ArffReader:\n",
        "    \"\"\"Classe para ler arquivos no formato ARFF (Attribute-Relation File Format)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Construtor da classe - inicializa listas vazias para atributos e dados\"\"\"\n",
        "        self.attributes = []  # Lista para armazenar os nomes dos atributos\n",
        "        self.data = []  # Lista para armazenar os dados/inst√¢ncias\n",
        "\n",
        "    def read_arff(self, input_file):\n",
        "        \"\"\"M√©todo para ler um arquivo ARFF e extrair atributos e dados\"\"\"\n",
        "        reading_data = False  # Flag para indicar se estamos lendo a se√ß√£o de dados\n",
        "        try:\n",
        "            # Abre o arquivo em modo leitura com codifica√ß√£o UTF-8\n",
        "            with open(input_file, 'r', encoding='utf-8') as file:\n",
        "                # Itera sobre cada linha do arquivo\n",
        "                for line in file:\n",
        "                    line = line.strip()  # Remove espa√ßos em branco no in√≠cio e fim da linha\n",
        "                    # Pula linhas vazias ou coment√°rios (que come√ßam com %)\n",
        "                    if not line or line.startswith('%'):\n",
        "                        continue\n",
        "                    # Se a linha cont√©m '@attribute', extrai o nome do atributo\n",
        "                    if '@attribute' in line.lower():\n",
        "                        attr_name = line.split()[1]  # Pega o segundo elemento (nome do atributo)\n",
        "                        self.attributes.append(attr_name)  # Adiciona √† lista de atributos\n",
        "                        continue\n",
        "                    # Se encontrou '@data', marca que come√ßamos a ler os dados\n",
        "                    if '@data' in line.lower():\n",
        "                        reading_data = True\n",
        "                        continue\n",
        "                    # Se estamos na se√ß√£o de dados, processa a linha\n",
        "                    if reading_data:\n",
        "                        self.data.append(line.split(','))  # Divide a linha por v√≠rgulas e adiciona aos dados\n",
        "            # Imprime informa√ß√µes sobre o arquivo lido\n",
        "            print(f\"Total d'attributs : {len(self.attributes)}\")\n",
        "            print(f\"Total d'instances : {len(self.data)}\")\n",
        "        except Exception as e:\n",
        "            # Se houver erro, imprime a mensagem e relan√ßa a exce√ß√£o\n",
        "            print(f\"Erreur lors de la lecture du fichier : {str(e)}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "def build_ancestors(labels):\n",
        "    \"\"\"Fun√ß√£o para construir um dicion√°rio de ancestrais para cada label na hierarquia\"\"\"\n",
        "    ancestors = defaultdict(list)  # Cria dicion√°rio com lista vazia como valor padr√£o\n",
        "    # Para cada par de labels, verifica se um √© ancestral do outro\n",
        "    for label1 in labels:\n",
        "        for label2 in labels:\n",
        "            # Se label2 est√° contido em label1, ent√£o label2 √© ancestral de label1\n",
        "            if label2 in label1:\n",
        "                ancestors[label1].append(label2)  # Adiciona label2 como ancestral de label1\n",
        "    return dict(ancestors)  # Converte defaultdict para dict normal\n",
        "\n",
        "class HierarchicalGlobalNaivesBayes:\n",
        "    \"\"\"Classe que implementa o algoritmo Naive Bayes Hier√°rquico Global\"\"\"\n",
        "\n",
        "    def __init__(self, hierarchy, alpha=1):\n",
        "        \"\"\"Construtor da classe\"\"\"\n",
        "        # Constr√≥i a hierarquia completa a partir da hierarquia fornecida\n",
        "        self.labels = self.build_complet_hierarchy(hierarchy)\n",
        "        self.alpha = alpha  # Par√¢metro de suaviza√ß√£o de Laplace\n",
        "        self.descendants = {}  # Dicion√°rio para armazenar descendentes de cada classe\n",
        "        self.ancestors = {}  # Dicion√°rio para armazenar ancestrais de cada classe\n",
        "\n",
        "\n",
        "    def build_complet_hierarchy(self, hierarchy):\n",
        "        \"\"\"M√©todo para construir a hierarquia completa incluindo todos os n√≠veis\"\"\"\n",
        "        complet_hierarchy = []  # Lista para armazenar a hierarquia completa\n",
        "        # Para cada classe na hierarquia original\n",
        "        for classe in hierarchy:\n",
        "            # Para cada n√≠vel da classe (separado por pontos)\n",
        "            for _ in range(len(classe.split('.'))):\n",
        "                # Se a classe ainda n√£o est√° na hierarquia completa, adiciona\n",
        "                if classe not in complet_hierarchy:\n",
        "                    complet_hierarchy.append(classe)\n",
        "                    # Remove o √∫ltimo n√≠vel da classe (vai subindo na hierarquia)\n",
        "                    classe = classe.split('.')[:-1]\n",
        "                    # Se sobrou apenas um elemento (raiz), para o loop\n",
        "                    if len(classe) == 1: # Sobrou so o R\n",
        "                        break\n",
        "                    # Reconstr√≥i a string da classe\n",
        "                    classe = '.'.join(classe)\n",
        "        return complet_hierarchy\n",
        "\n",
        "\n",
        "    def build_descendants(self, labels):\n",
        "        \"\"\"M√©todo para construir um dicion√°rio de descendentes para cada label\"\"\"\n",
        "        descendants = defaultdict(list)  # Cria dicion√°rio com lista vazia como valor padr√£o\n",
        "        # Para cada par de labels, verifica rela√ß√£o de descend√™ncia\n",
        "        for label1 in labels:\n",
        "            for label2 in labels:\n",
        "                # Se label2 est√° contido em label1, ent√£o label1 √© descendente de label2\n",
        "                if label2 in label1:\n",
        "                    descendants[label2].append(label1)  # Adiciona label1 como descendente de label2\n",
        "        return dict(descendants)  # Converte para dict normal\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"M√©todo para treinar o modelo com os dados de treino\"\"\"\n",
        "        n_samples, n_features = X.shape  # Obt√©m n√∫mero de amostras e caracter√≠sticas\n",
        "        # Constr√≥i dicion√°rios de descendentes e ancestrais\n",
        "        self.descendants = self.build_descendants(self.labels)\n",
        "        self.ancestors = build_ancestors(self.labels)\n",
        "\n",
        "        # Lista com um dicion√°rio para cada feature para armazenar probabilidades\n",
        "        self.feature_probs = [{} for _ in range(n_features)]\n",
        "        # Dicion√°rio para armazenar probabilidades a priori de cada classe\n",
        "        self.prior_prob = {classe: 0 for classe in self.labels}\n",
        "\n",
        "        # N√∫mero de valores √∫nicos por atributo, usado na suaviza√ß√£o de Laplace\n",
        "        self.n_values_per_att = {}\n",
        "        for feature_idx in range(n_features):\n",
        "            self.n_values_per_att[feature_idx] = len(np.unique(X[:, feature_idx]))\n",
        "\n",
        "        # N√∫mero de ocorr√™ncias de cada classe, usado na suaviza√ß√£o de Laplace\n",
        "        self.n_class_occurances = {}\n",
        "        classe, counts = np.unique(y, return_counts=True)  # Conta ocorr√™ncias de cada classe\n",
        "        for c, count in zip(classe, counts):\n",
        "            self.n_class_occurances[c] = count  # Armazena contagem para cada classe\n",
        "\n",
        "        # Para cada classe nos labels\n",
        "        for idx, c in enumerate(self.labels):\n",
        "            # Seleciona as inst√¢ncias que pertencem √† classe atual\n",
        "            X_c = X[y == c]\n",
        "            n_instancias_classe_c = X_c.shape[0]  # N√∫mero de inst√¢ncias da classe c\n",
        "\n",
        "            # Para cada feature, calcula as probabilidades condicionais\n",
        "            for feature_idx in range(n_features):\n",
        "                # Obt√©m valores √∫nicos e suas contagens para esta feature\n",
        "                feature_vals, counts = np.unique(X_c[:, feature_idx], return_counts=True)\n",
        "                n_valores_unicos_feat = len(np.unique(X_c[:, feature_idx]))\n",
        "\n",
        "                # Calcula probabilidade P(feature_val|classe) usando suaviza√ß√£o de Laplace\n",
        "                # Armazena em um dicion√°rio pares (valor do atributo, probabilidade)\n",
        "                feature_prob = {val: (count + self.alpha) / (n_instancias_classe_c + self.alpha * n_valores_unicos_feat) for val, count in zip(feature_vals, counts)}\n",
        "\n",
        "                # Armazena as probabilidades desta feature para esta classe\n",
        "                self.feature_probs[feature_idx][c] = feature_prob\n",
        "\n",
        "            # Soma a contagem da classe atual em todos os seus ancestrais\n",
        "            for classe in self.ancestors[c]:\n",
        "                self.prior_prob[classe] += n_instancias_classe_c + self.alpha\n",
        "\n",
        "        # Normaliza as probabilidades a priori usando a f√≥rmula de Laplace\n",
        "        for classe in self.prior_prob:\n",
        "            self.prior_prob[classe] /= (n_samples + (self.alpha * len(self.labels)))\n",
        "\n",
        "    def calculate_usefullness(self):\n",
        "        \"\"\"M√©todo para calcular a utilidade de cada classe baseada no tamanho da √°rvore\"\"\"\n",
        "        # Encontra o tamanho m√°ximo da √°rvore (maior n√∫mero de descendentes)\n",
        "        max_tree_size = max([len(value) for key, value in self.descendants.items()])\n",
        "        usefullness = []  # Lista para armazenar utilidades\n",
        "        # Para cada classe, calcula sua utilidade\n",
        "        for c in self.labels:\n",
        "            tree_size_i = len(self.descendants[c])  # Tamanho da √°rvore para esta classe\n",
        "            # F√≥rmula da utilidade: 1 - (log2(tamanho_arvore) / tamanho_max_arvore)\n",
        "            usefullness_i = 1 - (np.log2(tree_size_i) / max_tree_size)\n",
        "            usefullness.append(usefullness_i)  # Adiciona √† lista\n",
        "        return usefullness\n",
        "\n",
        "    def predict(self, X_test, usefullness=False):\n",
        "        \"\"\"M√©todo para fazer predi√ß√µes em dados de teste\"\"\"\n",
        "        # Se deve usar fator de utilidade, calcula as utilidades\n",
        "        if usefullness:\n",
        "            usefullness_list = self.calculate_usefullness()\n",
        "        X_test = X_test.astype(np.float64)  # Converte dados de teste para float64\n",
        "        predictions = []  # Lista para armazenar predi√ß√µes\n",
        "\n",
        "        # Para cada inst√¢ncia que se deseja predizer\n",
        "        for x in X_test:\n",
        "            posteriors = []  # Lista para armazenar probabilidades posteriores\n",
        "            # Para cada classe poss√≠vel\n",
        "            for idx, c in enumerate(self.labels):\n",
        "                # Calcula log(P(c)) + log(P(x1|c)) + log(P(x2|c)) + ... + log(P(xn|c))\n",
        "                # Obt√©m a probabilidade a priori da classe (em log)\n",
        "                prior = np.log(self.prior_prob[c])\n",
        "\n",
        "                likelihood = 0  # Inicializa likelihood\n",
        "                # Para cada feature da inst√¢ncia\n",
        "                for feature_idx, feature_val in enumerate(x):\n",
        "                    feature_val = int(feature_val)  # Converte para inteiro\n",
        "                    # Verifica se este valor da feature existe para esta classe\n",
        "                    if feature_val in self.feature_probs[feature_idx][c]:\n",
        "                        # Soma o log da probabilidade P(feature_val|classe)\n",
        "                        likelihood += np.log(self.feature_probs[feature_idx][c][feature_val])\n",
        "                    else:\n",
        "                        # Se n√£o existe, usa suaviza√ß√£o de Laplace para estimar\n",
        "                        nvals = float(self.n_values_per_att[feature_idx])\n",
        "                        likelihood += np.log(self.alpha / (self.n_class_occurances.get(c, 0) + nvals*self.alpha))\n",
        "\n",
        "                # Calcula probabilidade posterior: prior + likelihood\n",
        "                posterior = prior + likelihood\n",
        "                # Se deve usar utilidade, adiciona o log da utilidade\n",
        "                if usefullness:\n",
        "                    posterior += np.log(usefullness_list[idx])\n",
        "                posteriors.append(posterior)  # Adiciona √† lista de posteriores\n",
        "\n",
        "            # Escolhe a classe com maior probabilidade posterior\n",
        "            # np.argmax retorna o √≠ndice que maximiza o array \"posteriors\"\n",
        "            predictions.append(self.labels[np.argmax(posteriors)])\n",
        "\n",
        "        return np.array(predictions)  # Retorna array numpy com as predi√ß√µes\n",
        "\n",
        "def metrics_hierarquica(predictions, y_true, labels):\n",
        "    \"\"\"Fun√ß√£o para calcular m√©tricas hier√°rquicas (precis√£o, recall e F1)\"\"\"\n",
        "    ancestors = build_ancestors(labels)  # Constr√≥i dicion√°rio de ancestrais\n",
        "    numerador = 0  # Numerador para precis√£o e recall\n",
        "    denominador_precision = 0  # Denominador para precis√£o\n",
        "    denominador_recall = 0  # Denominador para recall\n",
        "\n",
        "    # Para cada par (predi√ß√£o, valor verdadeiro)\n",
        "    for classe_predita, classe_verdadeira in zip(predictions, y_true):\n",
        "        # Obt√©m ancestrais da classe predita e verdadeira\n",
        "        ancestrais_classe_predita = ancestors.get(classe_predita, [])\n",
        "        ancestrais_classe_verdadeira = ancestors.get(classe_verdadeira, [])\n",
        "        classes_comum = 0  # Conta classes em comum\n",
        "\n",
        "        # Conta quantas classes ancestrais s√£o comuns\n",
        "        for c1 in ancestrais_classe_predita:\n",
        "            for c2 in ancestrais_classe_verdadeira:\n",
        "                if c1 == c2:\n",
        "                    classes_comum += 1\n",
        "\n",
        "        # Acumula valores para c√°lculo das m√©tricas\n",
        "        numerador += classes_comum\n",
        "        denominador_precision += len(ancestrais_classe_predita)\n",
        "        denominador_recall += len(ancestrais_classe_verdadeira)\n",
        "\n",
        "    # Calcula precis√£o hier√°rquica\n",
        "    hierarchical_precision = numerador / denominador_precision if denominador_precision != 0 else 0\n",
        "    # Calcula recall hier√°rquico\n",
        "    hierarchical_recall = numerador / denominador_recall if denominador_recall != 0 else 0\n",
        "\n",
        "    # Calcula F1-score hier√°rquico\n",
        "    if hierarchical_precision + hierarchical_recall == 0:\n",
        "        f_measure = 0\n",
        "    else:\n",
        "        f_measure = (2 * hierarchical_precision * hierarchical_recall) / (hierarchical_precision + hierarchical_recall)\n",
        "\n",
        "    return hierarchical_precision, hierarchical_recall, f_measure\n",
        "\n",
        "\n",
        "def main(train_file_path, test_file_path, alpha):\n",
        "    \"\"\"Fun√ß√£o principal que executa todo o pipeline de treinamento e teste\"\"\"\n",
        "    print(\"üìñ Lecture du fichier d'entra√Ænement...\")\n",
        "    # Cria leitor para arquivo de treino\n",
        "    train_reader = ArffReader()\n",
        "    train_reader.read_arff(train_file_path)  # L√™ arquivo de treino\n",
        "\n",
        "    # Converte dados de treino para array numpy\n",
        "    # Remove √∫ltima coluna (r√≥tulo) e converte para float, substituindo '?' por 0.0\n",
        "    X_train = np.array([\n",
        "        list(map(lambda x: float(x) if x and x != '?' else 0.0, row[:-1]))\n",
        "        for row in train_reader.data\n",
        "    ])\n",
        "    # Extrai r√≥tulos (√∫ltima coluna) como array numpy\n",
        "    y_train = np.array([row[-1] for row in train_reader.data])\n",
        "\n",
        "    print(\"üìñ Lecture du fichier de test...\")\n",
        "    # Cria leitor para arquivo de teste\n",
        "    test_reader = ArffReader()\n",
        "    test_reader.read_arff(test_file_path)  # L√™ arquivo de teste\n",
        "\n",
        "    # Converte dados de teste para array numpy (mesmo processo que treino)\n",
        "    X_test = np.array([\n",
        "        list(map(lambda x: float(x) if x and x != '?' else 0.0, row[:-1]))\n",
        "        for row in test_reader.data\n",
        "    ])\n",
        "    # Extrai r√≥tulos de teste\n",
        "    y_test = np.array([row[-1] for row in test_reader.data])\n",
        "\n",
        "    # Imprime informa√ß√µes sobre os dados\n",
        "    print(f\"\\n=== Test avec alpha = {alpha} ===\")\n",
        "    print(f\"üìä Donn√©es d'entra√Ænement: {len(X_train)} instances\")\n",
        "    print(f\"üìä Donn√©es de test: {len(X_test)} instances\")\n",
        "\n",
        "    # Obt√©m hierarquia √∫nica dos r√≥tulos de treino\n",
        "    hierarchy = np.unique(y_train)\n",
        "    print(f\"Hi√©rarchie d√©tect√©e: {len(hierarchy)} classes\")\n",
        "\n",
        "    # Cria e treina o modelo\n",
        "    model = HierarchicalGlobalNaivesBayes(hierarchy, alpha=alpha)\n",
        "    print(\"Entra√Ænement du mod√®le...\")\n",
        "    model.fit(X_train, y_train)  # Treina o modelo\n",
        "\n",
        "    # Faz predi√ß√µes sem fator de utilidade\n",
        "    print(\"\\nüîç R√©sultats sans facteur d'utilit√©:\")\n",
        "    y_pred = model.predict(X_test, usefullness=False)\n",
        "\n",
        "    # Calcula m√©tricas hier√°rquicas\n",
        "    hierarchical_precision, hierarchical_recall, f1 = metrics_hierarquica(y_pred, y_test, model.labels)\n",
        "\n",
        "    # Imprime resultados\n",
        "    #print(f\"hierarchical_precision (hp): {hierarchical_precision * 100:.2f}%\")\n",
        "    #print(f\"hierarchical_recall (hR): {hierarchical_recall * 100:.2f}%\")\n",
        "    print(f\"F1-score hi√©rarchique (hF): {f1 * 100:.2f}%\")\n",
        "\n",
        "\n",
        "# Bloco principal - executa apenas se o script for executado diretamente\n",
        "if __name__ == \"__main__\":\n",
        "    # Define caminhos dos arquivos de treino e teste\n",
        "    train_file_path = \"/content/GPCR-PfamTRA0.arff\"\n",
        "    test_file_path = \"/content/GPCR-PfamTES0.arff\"\n",
        "    # Testa com alpha = 1.0\n",
        "    for alpha in [1.0,0.01,0.1]:\n",
        "        main(train_file_path, test_file_path, alpha)"
      ]
    }
  ]
}